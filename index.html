<!DOCTYPE HTML>
<html lang="en">

<head>
  <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

  <title>Zhuohang Jiang</title>

  <meta name="author" content="Zhuohang Jiang">
  <meta name="viewport" content="width=device-width, initial-scale=1">

  <link rel="stylesheet" type="text/css" href="stylesheet.css">
  <link rel="icon"
    href="data:image/svg+xml,<svg xmlns=%22http://www.w3.org/2000/svg%22 viewBox=%220 0 100 100%22><text y=%22.9em%22 font-size=%2290%22>üåê</text></svg>">
</head>

<body>
  <table
    style="width:100%;max-width:800px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
    <tbody>
      <tr style="padding:0px">
        <td style="padding:0px">
          <table
            style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
            <tbody>
              <tr style="padding:0px">
                <td style="padding:2.5%;width:63%;vertical-align:middle">
                  <p style="text-align:center">
                    <name>Zhuohang Jiang</name>
                  </p>
                  <p>I am an undergraduate student at <a href="https://www.scu.edu.cn">Sichuan
                      University(SCU)</a>,majoring in Computer Science & technology. My
                    <strong> Major GPA (CS cources):
                      3.79/4, 89.39/100;</strong>
                    Overall GPA: 3.78/4, 89.25/100
                  </p>
                  <p>
                    In the Sichuan University, I am working as a research assistant at
                    <a href="http://www.machineilab.org/">MachineILab</a>
                    since 2022, advised by
                    <a href="https://scholar.google.com/citations?user=-cNWmJMAAAAJ&hl=zh-CN">Prof. JiZhe Zhou</a>.
                    I am participating in one National Natural Science Foundation of China and one National Key R&D
                    Program of China.
                  </p>
                  <p style="text-align:center">
                    <a href="mailto:zhuohangjiang2002@gmail.com">Email</a> &nbsp/&nbsp
                    <a href="data/ZhuohangJiang-CV.pdf">CV</a> &nbsp/&nbsp
                    <!-- <a href="https://scholar.google.com/citations?hl=en&user=jktWnL8AAAAJ">Google Scholar</a> -->
                    <!-- &nbsp/&nbsp -->
                    <a href="https://github.com/jzzzzh">Github</a>&nbsp/&nbsp
                    <a href="https://www.zhihu.com/people/jzh-8-11">Zhihu</a>
                  </p>
                </td>
                <td style="padding:2.5%;width:40%;max-width:40%">
                  <a href="images/ZhuoHangJiang_casual.jpg"><img style="width:100%;max-width:100%" alt="profile photo"
                      src="images/ZhuoHangJiang_casual_circle.png" class="hoverZoomLink"></a>
                </td>
              </tr>
            </tbody>
          </table>
          <table
            style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
            <tbody>
              <tr>
                <td style="padding:20px;width:100%;vertical-align:middle">
                  <heading>Research Topics</heading>
                  <p>
                    I'm interested in <strong>computer vision, machine learning, and causal inference</strong>.Much of
                    my
                    research is about generate SCM(structual causal model) and NCM(neural causal model) which help the
                    neural network soluble.My
                    goal is to build soluble neural network which can be next generation of general artificial
                    Intelligence with <strong>low parameter model</strong> . Hoping the <strong>combination of causal
                      models and other artificial
                      intelligence </strong> can achieve better training effects.
                    <!-- Representative Projects are <span class="highlight">highlighted -->
                    </span>.
                  </p>
                </td>
              </tr>
            </tbody>
          </table>
          <table
            style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
            <tbody>
              <tr>
                <td style="padding:20px;width:100%;vertical-align:middle">
                  <heading>Publications</heading>
                </td>
              </tr>
            </tbody>
          </table>
          <table
            style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
            <tbody>
              <tr>
                <td style="padding:0px 20px 20px 20px;width:100%;vertical-align:middle">
                  <!-- <a href="under-review.html" id="AutoCost"> -->

                  <papertitle>Not Only Pre‚Äëtrain: Perceptual MAE for Image Manipulation Localization</papertitle>
                  <br>
                  XiAOCHEN MA, <b>ZHUOHANG JiANG</b>, AND JiZHE ZHOU
                  <br>
                  ACM MM 2023(manuscript under review)
                  <br>
                  <font color='gray'> This necessitates IML models to carry out a semantic understanding of the entire
                    image. In this paper, we
                    reformulate the IML task as a high‚Äëlevel
                    vision task that greatly benefits from low‚Äëlevel features. We propose a method to enhance the Masked
                    Autoencoder (MAE) by incorporating
                    high‚Äëresolution inputs and a perceptual loss supervision module, which we term Perceptual MAE
                    (PMAE). While
                    MAE has demonstrated an
                    impressive understanding of object semantics, PMAE can also comprehend low‚Äëlevel semantics with our
                    proposed
                    enhancements. This
                    paradigm effectively unites the low‚Äëlevel and high‚Äëlevel features of the IML task and outperforms
                    state‚Äëof‚Äëthe‚Äëart tampering localization methods
                    on five publicly available datasets, as evidenced by extensive experiments.</font>
                </td>
              </tr>
            </tbody>
          </table>
          <table
            style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
            <tbody>
              <tr>
                <td style="padding:0px 20px 20px 20px;width:100%;vertical-align:middle">
                  <!-- <a href="under-review.html" id="AutoCost"> -->
                  <papertitle>Contour‚ÄëAware Contrastive Learning for Image Manipulation Localization</papertitle>
                  <br>
                  QiN Li, CHUNFANG YU, <b>ZHUOHANG JiANG</b>, AND JiZHE ZHOU
                  <br>
                  TIP 2023(manuscript under review)
                  <br>
                  <font color='gray'>We propose a novel Contour‚Äëaware Contrastive Learning Network (CaCL‚ÄëNet) based on
                    the encoder‚Äëdecoder architecture. On the encoder side,
                    since the contour is foremost concerned in IML, we consider the image patches sampled along the
                    manipulation contour are the hard examples
                    and set them as the anchor. The patches of pure tampered and authentic pixels are set as positives
                    and negatives respectively to conduct
                    contrastive learning. The decoder then manages to specify the manipulated regions and restores the
                    explicit contours of the manipulations
                    through the proposed Contour Binary Cross‚ÄëEntropy (CBCE) loss.
                  </font>
                </td>
              </tr>
            </tbody>
          </table>


          <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
            <tbody>
              <tr>
                <td>
                  <heading>Research Projects</heading>
                </td>
              </tr>
            </tbody>
          </table>
          <table
            style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
            <tbody>
              <tr>
                <td style="padding:0px 20px 20px 20px;width:100%;vertical-align:middle">
                  <!-- <a href="under-review.html" id="AutoCost"> -->

                  <papertitle>Research on Scene Graph Structure Learning Method for Private Object Detection
                  </papertitle>

                  <br>
                  Advisor: Jizhe Zhou
                  <br>
                  <strong> Participate as an intern</strong>
                  <br>
                  <em>National Natural Science Foundation of China </em>,&nbsp;2024&nbsp;
                  <br>
                  <font color='gray'>The privacy-sensitive object detection problem reauires the model to locate private
                    objects in bounding boxes on images or videos. Research on privacy-sensitive object detection has
                    imnortant value for personal-privacyprotection. Privacy-sensitive ob ject detection is actually a
                    scene reasoning problem. However existing privacy-sensitive oh iect detection methods are all
                    basedon the object detection framework.Due to the lack of scene reasoning ability,existing methods
                    suffer from detection accuracy,generalizability,and interpretability.This project intends to build a
                    set of privacy-sensitive objectdetection methods with scene reasoning capability through scene
                    graphs. Unlikeother tasks, privacy-sensitive object detection requires a non-parametric scenegraph
                    structure to keep the graph sparseÔºådynamicÔºåand interpretable.Therefore,this project correspondingly
                    proposes the scene graph structure learning methods.By studying 1) the distillation method of the
                    graph structure to sparse the scenegraphÔºå2) the transferring method between the scene graphs of
                    different frames tomake the scene graph dynamicÔºå3) the privacy-rule reasoning method based on
                    thescene graph structureÔºåsolves the problem of scene graph generation with thenon-parametric graph
                    structureÔºå builds a new privacy-sensitive object detectionframework based on scene reasoningÔºå break
                    the bottlenecks of privacy-sensitiveobject detection methods in accuracyÔºågeneralizability,and
                    interpretability.Thisprivacy-sensitive object detection framework also enriched the theoretical
                    framework and application scenarios of neural networks.</font>
                </td>
              </tr>
            </tbody>
          </table>
          <table
            style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
            <tbody>
              <tr>
                <td style="padding:0px 20px 20px 20px;width:100%;vertical-align:middle">
                  <!-- <a href="under-review.html" id="AutoCost"> -->

                  <papertitle>Intelligent control and full life feedforward deduction technology through pre planning
                    and post evaluation</papertitle>

                  <br>
                  Advisor: Jizhe Zhou
                  <br>
                  <strong> Participate as an intern</strong>
                  <br>
                  <em>National Key R&D
                    Program of China</em>,&nbsp;2023&nbsp;
                  <br>
                  <font color='gray'>This topic proposes to adopt the scheme of "first completing information, then path
                    reasoning". Specifically, this sub project intends to improve the initial network diagram based on
                    the data base established in previous projects and further consider the frequency of common
                    occurrence of impact factors. Then, based on the external knowledge causal information completion
                    method of remote supervision, the network graph is again completed and cleaned, and then a path
                    reasoning algorithm based on depth first traversal of the graph is used to achieve feedforward
                    reasoning. Finally, a human-computer interactive network information verification method based on
                    uncertainty reasoning is used to revise the causal relationship in the network diagram again based
                    on artificial feedback on the reasoning path, further improving the accuracy and recall rate of the
                    path reasoning algorithm results.</font>
                </td>
              </tr>
            </tbody>
          </table>

          <table
            style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
            <tbody>
              <tr>
                <td style="padding:0px 20px 20px 20px;width:100%;vertical-align:middle">
                  <!-- <a href="under-review.html" id="AutoCost"> -->

                  <papertitle>"Listening" ‚Äë A Seismic Audio Detection System Based on Deep Learning</papertitle>

                  <br>
                  <b>Zhuohang Jiang</b>, Zhaoyi Liu, Zhuoyao Fan, Wendian Luo, Haoda Di
                  <br>
                  <em>Innovation and Entrepreneurship Project for College Students</em>,&nbsp;2023&nbsp;
                  <br>
                  <em>National level projects</em>
                  <br>
                  <font color='gray'>The project aims to use the TPTMC audio noise reduction model and the Whisper
                    speech recognition model to form a pipeline and deploy the algorithm to edge devices to create a
                    life audio detection system. The system aims to reduce environmental noise interference,
                    intelligently determine the buried location, reduce the difficulty of use, and achieve rapid
                    deployment during the golden search and rescue period, significantly improving the success rate of
                    search and rescue and increasing the survival rate of the wounded.</font>
                </td>
              </tr>
            </tbody>
          </table>


          <table
            style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
            <tbody>
              <tr>
                <td style="padding:0px 20px 20px 20px;width:100%;vertical-align:middle">
                  <!-- <a href="under-review.html" id="AutoCost"> -->

                  <papertitle>"Dazzling Shadow" - 2D and 3D game material generation system based on textureGAN and
                    pixel NeRF technology</papertitle>

                  <br>
                  Xiaocheng Ma, Zihan Liu, <b>Zhuohang Jiang</b>, Guofeng Ding, Li Ju
                  <br>
                  <em>Innovation and Entrepreneurship Project for College Students</em>,&nbsp;2022&nbsp;
                  <br>
                  <em>National level projects</em>
                  <br>
                  <font color='gray'>With the vigorous development of the game industry at home and abroad, players'
                    requirements for the quality of game art have increased. However, small and medium-sized game
                    studios are difficult to bear the labor costs of high-quality art professionals. Therefore, there is
                    an urgent need for an efficient 2D and 3D game material automatic generation system to provide
                    high-quality game material. This project plans to develop a system that can easily generate game
                    image materials through a GAN variant supplemented by 3D reconstruction technology based on neural
                    networks. By inputting multiple modal information such as text, draft, and texture, it can quickly
                    generate 2D and 3D image materials required by users, significantly improving the efficiency of
                    material generation and reducing development costs.</font>
                </td>
              </tr>
            </tbody>
          </table>
          <table
            style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
            <tbody>
              <tr>
                <td style="padding:0px 20px 20px 20px;width:100%;vertical-align:middle">
                  <!-- <a href="under-review.html" id="AutoCost"> -->

                  <papertitle>"Cabinets" - High throughput intelligent food pickup cabinets</papertitle>

                  <br>
                  Haoda Di, Xilin Wei, <b>Zhuohang Jiang</b>, Chengjie Liu
                  <br>
                  <em>Innovation and Entrepreneurship Project for College Students</em>,&nbsp;2022&nbsp;
                  <br>
                  <em>Provincial projects</em>
                  <br>
                  <font color='gray'>College students must face the problem of crowded cafeterias during peak meal
                    times. This project aims to achieve reservation through the development of an online food ordering
                    applet, coordinate with multi-channel intelligent food retrieval cabinets to achieve queuing and
                    multi-channel parallel reduction of queuing time, and combine Bluetooth beacon positioning to
                    allocate cabinets to the currently most needed people to improve utilization efficiency and reduce
                    the occupancy time of a single cabinet. Enable each college student to quickly pick up meals during
                    peak meal times, enhance the competitiveness of the cafeteria, and solve the problem of cafeteria
                    congestion. At the same time, during the epidemic, avoid large-scale personnel gathering and reduce
                    the risk of epidemic transmission.</font>
                </td>
              </tr>
            </tbody>
          </table>
          <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
            <tbody>
              <tr>
                <td>
                  <heading>Project Portfolio</heading>(selected)
                </td>
              </tr>
            </tbody>
          </table>
          <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
            <tbody>
              <tr>
                <td style="padding:0px 20px 0px 20px;width:100%;vertical-align:middle">
                  <!-- padding ‰∏ä Âè≥ ‰∏ã Â∑¶ -->
                  <a href="https://github.com/jzzzzh/I_AM_SCUER">
                    <papertitle>I AM SCUer</papertitle>
                  </a>
                </td>
              </tr>
            </tbody>
          </table>
          <br>
          <table
            style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
            <tbody>
              <tr>

                <td style="padding:0px 20px 0px 20px;width:25%;vertical-align:middle"><img src="images/IAMSCUER.jpg"
                    width="160" height="160"></td>
                <td width="75%" valign="center">
                  <p>A platform for generating related avatars of Sichuan University</p>
                  <p>More than <font color="red"><em><strong>1000+</strong></em></font> users used I AM SCUer in the SCU
                    campus.</p>
                </td>
              </tr>
            </tbody>
          </table>

          <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
            <tbody>
              <tr>
                <td style="padding:20px;width:100%;vertical-align:middle">
                  <heading>Education</heading>
                </td>
              </tr>
              <tr>
            </tbody>
          </table>

          <table
            style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
            <tbody>
              <tr>
                <td style="padding:0px 20px 20px 20px;width:75%;vertical-align:middle">
                  <b>Sichuan University</b>, Chengdu, Sichuan, China
                  <br>
                  B.E. in Computer Science and Technology ‚Ä¢ Sep. 2020 to present
                  </br>
                </td>
                <td style="padding:0px 20px 0px 20px;width:10%;vertical-align:middle"><img
                    src="images/SichuanUniversityLOGO.png" width="75" height="75"></td>
              </tr>
            </tbody>
          </table>

          <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
            <tbody>
              <tr>
                <td style="padding:20px;width:100%;vertical-align:middle">
                  <heading>Experience</heading>
                </td>
              </tr>
              <tr>
            </tbody>
          </table>

          <table
            style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
            <tbody>
              <tr>
                <td style="padding:0px 20px 20px 20px;width:75%;vertical-align:middle">
                  <a href="http://www.machineilab.org/"> MachineILab</a>, <b>Sichuan University</b>
                  <br>
                  Research Assistant ‚Ä¢ Sep. 2022 to present
                  <br>
                  Advisor: <a href="https://scholar.google.com/citations?user=-cNWmJMAAAAJ&hl=zh-CN"> Prof. JiZhe
                    Zhou</a>
                  </br>
                </td>
                <td style="padding:0px 20px 0px 20px;width:10%;vertical-align:middle"><img
                    src="images/SichuanUniversityLOGO.png" width="75" height="75"></td>
              </tr>
            </tbody>
          </table>
          <br>
          <table
            style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
            <tbody>
              <tr>
                <td style="padding:0px 20px 20px 20px;width:75%;vertical-align:middle">
                  <a href="https://github.com/covscript/covscript"> Covariant association</a>, <b>Sichuan University</b>
                  <br>
                  the president of the covariant association ‚Ä¢ Sep. 2022 to present
                  <br>
                  the Covariant association obtain at least <font color="red"><em><strong>400+</strong></em></font>
                  members, in which communicate the technology of the
                  computer science.
                </td>
                <td style="padding:0px 20px 0px 20px;width:10%;vertical-align:middle"><img src="images/covariant.jpg"
                    width="75" height="75"></td>
              </tr>
            </tbody>
          </table>
          <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
            <tbody>
              <tr>
                <td style="padding:20px;width:100%;vertical-align:middle">
                  <heading>Award</heading>
                  (selected)
                </td>
              </tr>
              <tr>
            </tbody>
          </table>
          <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
            <tbody>
              <tr>
                <td>
                  <strong> Mathematical Contest In Modeling(MCM/ICM)</strong> USA, 2022
                </td>
                <td style="width:10%;vertical-align:middle; width: 40%;">
                  <strong>Honorable Mention</strong>
                </td>
              </tr>
            </tbody>
          </table>
          <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
            <tbody>
              <tr>
                <td>
                  <strong>Computer Design Competition</strong> China, 2023
                </td>
                <td style="width:10%;vertical-align:middle; width: 40%;">
                  <strong>Provincial First Prize</strong>
                </td>
              </tr>
            </tbody>
          </table>
          <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
            <tbody>
              <tr>
                <td>
                  <strong>China Undergraduate Mathematical Contest in Modeling (CUMCM)</strong> China, 2022
                </td>
                <td style="width:10%;vertical-align:middle; width: 40%;">
                  <strong>Provincial Second Prize</strong>
                </td>
              </tr>
            </tbody>
          </table>
          <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
            <tbody>
              <tr>
                <td>
                  <strong>The Chinese Mathematics Competitions (CMC)</strong> Sichuan,China, 2022
                </td>
                <td style="width:10%;vertical-align:middle; width: 40%;">
                  <strong>Provincial Second Prize</strong>
                </td>
              </tr>
            </tbody>
          </table>

          <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
            <tbody>
              <tr>
                <td>
                  <strong>Blue Bridge Cup</strong> Sichuan,China, 2022
                </td>
                <td style="width:10%;vertical-align:middle; width: 40%;">
                  <strong>Provincial Third Prize</strong>
                </td>
              </tr>
            </tbody>
          </table>

          <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
            <tbody>
              <tr>
                <td>
                  <strong>Software Design Engineer</strong> China, 2022
                </td>
                <td style="width:10%;vertical-align:middle; width: 40%;">
                  <strong>Intermediate Engineer</strong>
                </td>
              </tr>
            </tbody>
          </table>

          <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
            <tbody>
              <tr>
                <td>
                  <strong>Comprehensive First Class Scholarship</strong> Sichuan University, Sichuan, China, 2022
                </td>
                <td style="width:10%;vertical-align:middle; width: 40%;">
                  <strong>Top 1%</strong>
                </td>
              </tr>
            </tbody>
          </table>

          <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
            <tbody>
              <tr>
                <td>
                  <strong>Tencent Scholarship</strong> Sichuan University, Sichuan, China, 2023
                </td>
                <td style="width:10%;vertical-align:middle; width: 40%;">
                  <strong>Top 2%</strong>
                </td>
              </tr>
            </tbody>
          </table>

          <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
            <tbody>
              <tr>
                <td>
                  <strong>Outstanding students of Sichuan University</strong> Sichuan University, Sichuan, China, 2022
                </td>
                <td style="width:10%;vertical-align:middle; width: 40%;">
                  <strong>Top 5%</strong>
                </td>
              </tr>
            </tbody>
          </table>

          <div style="text-align: center;">
            <a href="https://clustrmaps.com/site/1buac" title="Visit tracker">
              <img src="//www.clustrmaps.com/map_v2.png?d=arwquO5nouqZwMbhchX9awZ1bM3tO8fPWrcUr78F1E4&cl=ffffff" />
            </a>
          </div>
          <table
            style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
            <tbody>
              <tr>
                <td style="padding:20px">
                  <div style="float:left;">
                    Updated at Mar. 2023
                  </div>
                  <div style="float:right;">
                    Thanks <a href="https://jonbarron.info">Jon Barron</a> for this amazing template
                  </div>
                  <br>
                  <br>
                  <p></p>
                </td>
              </tr>
            </tbody>
          </table>
        </td>
      </tr>
  </table>
</body>


</html>